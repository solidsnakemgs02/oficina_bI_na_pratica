#importa dados, string vazio como NA, string como fatores
dados = read_csv("E:/Alex/2025/CEUB/Disciplinas/Introdução a R/Tarefas_Desafio/tempo.csv", sep = ";")
#importa dados, string vazio como NA, string como fatores
dados = read.csv("E:/Alex/2025/CEUB/Disciplinas/Introdução a R/Tarefas_Desafio/tempo.csv", sep = ";")
install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>%
group_by(Produto) %>%
summarise(Total = sum(Vendas))
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>%
group_by(Produto) %>%
summarise(Total = sum(Vendas))
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
install.packages("magrittr")
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
#install.packages("magrittr")
library(magrittr)
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
#install.packages("magrittr")
library(magrittr)
library(dplyr)
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>%
summarise(Total = sum(Vendas))
ggplot(data, aes(x = Produto, y = Vendas)) +
geom_bar(stat = "identity", fill = "steelblue")
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
#install.packages("magrittr")
library(magrittr)
library(dplyr)
library(ggplot2)
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
ggplot(data, aes(x = Produto, y = Vendas)) + geom_bar(stat = "identity", fill = "steelblue")
library(shiny)
ui <- fluidPage(
titlePanel("Meu Dashboard"),
sidebarLayout(
sidebarPanel(
sliderInput("num", "Escolha um número:", 1, 100, 50)
),
mainPanel(
textOutput("resultado")
)
)
)
server <- function(input, output) {
output$resultado <- renderText({
paste("Você escolheu o número", input$num)
})
}
shinyApp(ui = ui, server = server)
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
ui <- fluidPage(
titlePanel("Exemplo Shiny"),
sidebarLayout(
sidebarPanel(
sliderInput("num", "Escolha um numero:", 1, 100, 50)
),
mainPanel(
textOutput("resultado")
)
)
)
server <- function(input, output) {
output$resultado <- renderText({
paste("Voce escolheu o numero", input$num)
})
}
shinyApp(ui = ui, server = server)
library(shiny)
# Interface do Usuário
ui <- fluidPage(
titlePanel("Distribuição do MPG por nº de cilindros"),
sidebarLayout(
sidebarPanel(
selectInput(
inputId = "cyl_input",
label = "Escolha o nº de cilindros:",
choices = unique(mtcars$cyl),
selected = 4
)
),
mainPanel(
plotOutput("hist_mpg")
)
)
)
# Lógica do Servidor
server <- function(input, output) {
output$hist_mpg <- renderPlot({
# Filtrar o dataset com base no input
dados_filtrados <- mtcars[mtcars$cyl == input$cyl_input, ]
# Plotar histograma
hist(dados_filtrados$mpg,
main = paste("MPG -", input$cyl_input, "cilindros"),
xlab = "Milhas por Galão (MPG)",
col = "steelblue",
border = "white")
})
}
# Executar o App
shinyApp(ui = ui, server = server)
mtcars.summary()
mtcars
dim(mtcars)
# Pacotes necessários
library(e1071)     # Para SVM
library(class)     # Para KNN
library(caret)     # Para particionar dados e avaliação
library(dplyr)     # Para manipulação de dados
install(library(caret)
install.packages(caret)
install.packages("caret")
# Pacotes necessários
library(e1071)     # Para SVM
library(class)     # Para KNN
library(caret)     # Para particionar dados e avaliação
library(dplyr)     # Para manipulação de dados
# Carregando o dataset iris
data(iris)
# Definindo a semente para reprodutibilidade
set.seed(123)
set.seed
# Definindo a semente para reprodutibilidade
set.seed(123)
# Separando os dados em treino (70%) e teste (30%)
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[index, ]
test_data <- iris[-index, ]
# -------------------
# Modelo SVM
# -------------------
svm_model <- svm(Species ~ ., data = train_data, kernel = "linear")
# Predição com o modelo SVM
svm_pred <- predict(svm_model, test_data)
# Avaliação SVM
svm_cm <- confusionMatrix(svm_pred, test_data$Species)
cat("Acurácia SVM:\n")
print(svm_cm$overall['Accuracy'])
# -------------------
# Modelo K-NN
# -------------------
# Normalizando os dados (importante para KNN)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_norm <- as.data.frame(lapply(train_data[1:4], normalize))
test_norm <- as.data.frame(lapply(test_data[1:4], normalize))
# KNN com k = 3
knn_pred <- knn(train = train_norm, test = test_norm,
cl = train_data$Species, k = 3)
# Avaliação KNN
knn_cm <- confusionMatrix(knn_pred, test_data$Species)
cat("Acurácia K-NN (k=3):\n")
print(knn_cm$overall['Accuracy'])
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(e1071)     # SVM
library(class)     # KNN
library(caret)     # Particionamento e avaliação
library(dplyr)     # Manipulação de dados
library(ggplot2)   # Visualização
library(reshape2)  # Para matriz de confusão
# Carregar o dataset
data(iris)
set.seed(123)
# Gráfico de dispersão por espécie
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Distribuição das Espécies de Iris",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# 70% treino, 30% teste
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[index, ]
test_data  <- iris[-index, ]
svm_model <- svm(Species ~ ., data = train_data, kernel = "linear")
svm_pred <- predict(svm_model, test_data)
# Avaliação
svm_cm <- confusionMatrix(svm_pred, test_data$Species)
svm_cm$overall['Accuracy']
# Normalização
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
train_norm <- as.data.frame(lapply(train_data[1:4], normalize))
test_norm  <- as.data.frame(lapply(test_data[1:4], normalize))
# KNN
knn_pred <- knn(train = train_norm, test = test_norm,
cl = train_data$Species, k = 3)
# Avaliação
knn_cm <- confusionMatrix(knn_pred, test_data$Species)
knn_cm$overall['Accuracy']
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(e1071)     # SVM
library(caret)     # Particionamento e avaliação
library(dplyr)     # Manipulação de dados
library(ggplot2)   # Visualização
library(reshape2)  # Para matriz de confusão
# Carregar o dataset
data(iris)
set.seed(123)
library(e1071)     # SVM
library(caret)     # Particionamento e avaliação
library(dplyr)     # Manipulação de dados
library(ggplot2)   # Visualização
library(reshape2)  # Para matriz de confusão
# Carregar o dataset
data(iris)
set.seed(123)
# Gráfico de dispersão por espécie
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Distribuição das Espécies de Iris",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# 70% treino, 30% teste
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[index, ]
test_data  <- iris[-index, ]
svm_model <- svm(Species ~ ., data = train_data, kernel = "linear")
svm_pred <- predict(svm_model, test_data)
# Avaliação
svm_cm <- confusionMatrix(svm_pred, test_data$Species)
svm_cm$overall['Accuracy']
cm_df <- as.data.frame(as.table(svm_cm$table))
ggplot(cm_df, aes(x = Prediction, y = Reference, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), size = 5) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(title = "Matriz de Confusão - SVM") +
theme_minimal()
library(shiny)
library(ggplot2)
library(dplyr)
# Dataset de exemplo (vamos simular dados para este exemplo)
set.seed(123)
dados <- data.frame(
ano = rep(2010:2020, each = 5),
regiao = rep(c("Norte", "Nordeste", "Centro-Oeste", "Sudeste", "Sul"), times = 11),
taxa_desemprego = round(runif(55, 4, 14), 1)
)
# Interface
ui <- fluidPage(
titlePanel("Taxa de Desemprego por Região (2010–2020)"),
sidebarLayout(
sidebarPanel(
selectInput("regiao", "Selecione a Região:", choices = unique(dados$regiao), selected = "Sudeste", multiple = TRUE)
),
mainPanel(
plotOutput("plotDesemprego")
)
)
)
# Servidor
server <- function(input, output) {
dados_filtrados <- reactive({
dados %>% filter(regiao %in% input$regiao)
})
output$plotDesemprego <- renderPlot({
ggplot(dados_filtrados(), aes(x = ano, y = taxa_desemprego, color = regiao)) +
geom_line(size = 1.5) +
geom_point() +
theme_minimal() +
labs(x = "Ano", y = "Taxa de Desemprego (%)")
})
}
# Execução
shinyApp(ui = ui, server = server)
# Pacotes
library(cluster)
library(dbscan)
library(ggplot2)
library(dplyr)
library(factoextra)
# Dados
data(iris)
dados <- scale(iris[, 1:4])  # padronizar
# PCA
pca <- prcomp(dados)
pca_df <- as.data.frame(pca$x[, 1:2])  # apenas os dois primeiros componentes
## Agrupamento hierárquico
hc <- hclust(dist(dados), method = "ward.D2")
grupos_hc <- cutree(hc, k = 3)
## DBSCAN
db <- dbscan(dados, eps = 0.6, minPts = 5)
## MeanShift (aproximação usando density peaks via fpc)
# Alternativa viável em R: usar cluster::pam sobre estimativa de densidade
densidade <- density(pca_df$PC1 + pca_df$PC2)
centros <- which(densidade$y > quantile(densidade$y, 0.75))
grupos_ms <- pam(dados, k = 3)$clustering
# Visualização
pca_df$HC <- factor(grupos_hc)
pca_df$DBSCAN <- factor(db$cluster)
pca_df$MS <- factor(grupos_ms)
# Plot exemplo para comparação
ggplot(pca_df, aes(PC1, PC2, color = HC)) + geom_point(size = 3) + ggtitle("Hierárquico")
ggplot(pca_df, aes(PC1, PC2, color = DBSCAN)) + geom_point(size = 3) + ggtitle("DBSCAN")
ggplot(pca_df, aes(PC1, PC2, color = MS)) + geom_point(size = 3) + ggtitle("MeanShift (simulado)")
# Carrega bibliotecas necessarias para o processamento
library("tidyquant")
# Carrega bibliotecas necessarias para o processamento
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- fread('LOA_FINAL_GND_4.txt', sep = ';')
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- fread('SIGA_BRASIL_2020.csv', sep = ';')
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- read.csv('SIGA_BRASIL_2020.csv', sep = ';')
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv', sep = ';')
# Leitura da tabela via read.csv
setwd()
# Leitura da tabela via read.csv
caminho <- getwd()
caminho
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv', sep = ';')
# Carrega bibliotecas necessarias para o processamento
#install.packages("sf")
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv')
# Leitura da tabela via read.csv
caminho ='E:/Alex/Livano/IPEA/ipea-promob/dados_estatísticos/Demanda - Nelson/infere/script_R/'
SIGA_BRASIL_2020 <- read.csv(caminho + 'SIGA_BRASIL_2020.csv')
# Leitura da tabela via read.csv
caminho ='E:/Alex/Livano/IPEA/ipea-promob/dados_estatísticos/Demanda - Nelson/infere/script_R/'
SIGA_BRASIL_2020 <- read.csv(caminho ,'SIGA_BRASIL_2020.csv')
# Leitura da tabela via read.csv
caminho ='E:/Alex/Livano/IPEA/ipea-promob/dados_estatísticos/Demanda - Nelson/infere/script_R/'
arquivo = caminho + 'SIGA_BRASIL_2020.csv'
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv')
# Carrega bibliotecas necessarias para o processamento
#install.packages("sf")
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('dados_normalizados_siga_brasil.csv')
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('dados_normalizados_siga_brasil.csv')
# Carrega bibliotecas necessarias para o processamento
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- read.csv('LOA_2020.csv')
knitr::opts_chunk$set(echo = TRUE)
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
library(shiny); runApp('E:/Alex/2025/UCB/Semana de TI/BI na Prática/Aula - BI na Prática/P_01_Scatter_Plot-Dispersão.R')
library(shiny)
library(plotly)
ui <- fluidPage(
titlePanel("🍷 Scatter Plot - Relação entre Ingredientes"),
sidebarLayout(
sidebarPanel(
selectInput("x_axis", "Selecione o eixo X:", choices = colnames(datasets::wine)[1:13], selected = "Alcohol"),
selectInput("y_axis", "Selecione o eixo Y:", choices = colnames(datasets::wine)[1:13], selected = "Malic"),
),
mainPanel(
plotlyOutput("scatterPlot")
)
)
)
library(shiny)
library(plotly)
library(dplyr)
#Carrega conjunto de dados Iris
data(iris)
iris_df <- iris
head(iris_df)
summary(iris_df)
write.csv(iris, "iris.csv", row.names = FALSE)
write.csv(iris, "E:\Alex\2025\UCB\Semana de TI\BI na Prática\Oficina_BI_na_Prática\R\iris.csv", row.names = FALSE)
write.csv(iris, "E:/Alex/2025/UCB/Semana de TI/BI na Prática/Oficina_BI_na_Prática/R/iris.csv", row.names = FALSE)
library(shiny); runApp('E:/Alex/2025/UCB/Semana de TI/BI na Prática/Oficina_BI_na_Prática/R/P_05_Painel_Completo_iris.r')
runApp('E:/Alex/2025/UCB/Semana de TI/BI na Prática/Oficina_BI_na_Prática/R/P_05_Painel_Completo_iris.r')
