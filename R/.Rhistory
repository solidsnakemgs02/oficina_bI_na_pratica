#importa dados, string vazio como NA, string como fatores
dados = read_csv("E:/Alex/2025/CEUB/Disciplinas/Introdu√ß√£o a R/Tarefas_Desafio/tempo.csv", sep = ";")
#importa dados, string vazio como NA, string como fatores
dados = read.csv("E:/Alex/2025/CEUB/Disciplinas/Introdu√ß√£o a R/Tarefas_Desafio/tempo.csv", sep = ";")
install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>%
group_by(Produto) %>%
summarise(Total = sum(Vendas))
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>%
group_by(Produto) %>%
summarise(Total = sum(Vendas))
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
install.packages("magrittr")
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
#install.packages("magrittr")
library(magrittr)
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
#install.packages("magrittr")
library(magrittr)
library(dplyr)
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>%
summarise(Total = sum(Vendas))
ggplot(data, aes(x = Produto, y = Vendas)) +
geom_bar(stat = "identity", fill = "steelblue")
#install.packages(c("tidyverse", "readr", "dplyr", "ggplot2", "shiny"))
#install.packages("magrittr")
library(magrittr)
library(dplyr)
library(ggplot2)
data <- data.frame(
Produto = c("A", "B", "C", "A", "B"),
Vendas = c(100, 150, 200, 130, 180)
)
data %>% group_by(Produto) %>% summarise(Total = sum(Vendas))
ggplot(data, aes(x = Produto, y = Vendas)) + geom_bar(stat = "identity", fill = "steelblue")
library(shiny)
ui <- fluidPage(
titlePanel("Meu Dashboard"),
sidebarLayout(
sidebarPanel(
sliderInput("num", "Escolha um n√∫mero:", 1, 100, 50)
),
mainPanel(
textOutput("resultado")
)
)
)
server <- function(input, output) {
output$resultado <- renderText({
paste("Voc√™ escolheu o n√∫mero", input$num)
})
}
shinyApp(ui = ui, server = server)
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
ui <- fluidPage(
titlePanel("Exemplo Shiny"),
sidebarLayout(
sidebarPanel(
sliderInput("num", "Escolha um numero:", 1, 100, 50)
),
mainPanel(
textOutput("resultado")
)
)
)
server <- function(input, output) {
output$resultado <- renderText({
paste("Voce escolheu o numero", input$num)
})
}
shinyApp(ui = ui, server = server)
library(shiny)
# Interface do Usu√°rio
ui <- fluidPage(
titlePanel("Distribui√ß√£o do MPG por n¬∫ de cilindros"),
sidebarLayout(
sidebarPanel(
selectInput(
inputId = "cyl_input",
label = "Escolha o n¬∫ de cilindros:",
choices = unique(mtcars$cyl),
selected = 4
)
),
mainPanel(
plotOutput("hist_mpg")
)
)
)
# L√≥gica do Servidor
server <- function(input, output) {
output$hist_mpg <- renderPlot({
# Filtrar o dataset com base no input
dados_filtrados <- mtcars[mtcars$cyl == input$cyl_input, ]
# Plotar histograma
hist(dados_filtrados$mpg,
main = paste("MPG -", input$cyl_input, "cilindros"),
xlab = "Milhas por Gal√£o (MPG)",
col = "steelblue",
border = "white")
})
}
# Executar o App
shinyApp(ui = ui, server = server)
mtcars.summary()
mtcars
dim(mtcars)
# Pacotes necess√°rios
library(e1071)     # Para SVM
library(class)     # Para KNN
library(caret)     # Para particionar dados e avalia√ß√£o
library(dplyr)     # Para manipula√ß√£o de dados
install(library(caret)
install.packages(caret)
install.packages("caret")
# Pacotes necess√°rios
library(e1071)     # Para SVM
library(class)     # Para KNN
library(caret)     # Para particionar dados e avalia√ß√£o
library(dplyr)     # Para manipula√ß√£o de dados
# Carregando o dataset iris
data(iris)
# Definindo a semente para reprodutibilidade
set.seed(123)
set.seed
# Definindo a semente para reprodutibilidade
set.seed(123)
# Separando os dados em treino (70%) e teste (30%)
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[index, ]
test_data <- iris[-index, ]
# -------------------
# Modelo SVM
# -------------------
svm_model <- svm(Species ~ ., data = train_data, kernel = "linear")
# Predi√ß√£o com o modelo SVM
svm_pred <- predict(svm_model, test_data)
# Avalia√ß√£o SVM
svm_cm <- confusionMatrix(svm_pred, test_data$Species)
cat("Acur√°cia SVM:\n")
print(svm_cm$overall['Accuracy'])
# -------------------
# Modelo K-NN
# -------------------
# Normalizando os dados (importante para KNN)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_norm <- as.data.frame(lapply(train_data[1:4], normalize))
test_norm <- as.data.frame(lapply(test_data[1:4], normalize))
# KNN com k = 3
knn_pred <- knn(train = train_norm, test = test_norm,
cl = train_data$Species, k = 3)
# Avalia√ß√£o KNN
knn_cm <- confusionMatrix(knn_pred, test_data$Species)
cat("Acur√°cia K-NN (k=3):\n")
print(knn_cm$overall['Accuracy'])
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(e1071)     # SVM
library(class)     # KNN
library(caret)     # Particionamento e avalia√ß√£o
library(dplyr)     # Manipula√ß√£o de dados
library(ggplot2)   # Visualiza√ß√£o
library(reshape2)  # Para matriz de confus√£o
# Carregar o dataset
data(iris)
set.seed(123)
# Gr√°fico de dispers√£o por esp√©cie
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Distribui√ß√£o das Esp√©cies de Iris",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# 70% treino, 30% teste
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[index, ]
test_data  <- iris[-index, ]
svm_model <- svm(Species ~ ., data = train_data, kernel = "linear")
svm_pred <- predict(svm_model, test_data)
# Avalia√ß√£o
svm_cm <- confusionMatrix(svm_pred, test_data$Species)
svm_cm$overall['Accuracy']
# Normaliza√ß√£o
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
train_norm <- as.data.frame(lapply(train_data[1:4], normalize))
test_norm  <- as.data.frame(lapply(test_data[1:4], normalize))
# KNN
knn_pred <- knn(train = train_norm, test = test_norm,
cl = train_data$Species, k = 3)
# Avalia√ß√£o
knn_cm <- confusionMatrix(knn_pred, test_data$Species)
knn_cm$overall['Accuracy']
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(e1071)     # SVM
library(caret)     # Particionamento e avalia√ß√£o
library(dplyr)     # Manipula√ß√£o de dados
library(ggplot2)   # Visualiza√ß√£o
library(reshape2)  # Para matriz de confus√£o
# Carregar o dataset
data(iris)
set.seed(123)
library(e1071)     # SVM
library(caret)     # Particionamento e avalia√ß√£o
library(dplyr)     # Manipula√ß√£o de dados
library(ggplot2)   # Visualiza√ß√£o
library(reshape2)  # Para matriz de confus√£o
# Carregar o dataset
data(iris)
set.seed(123)
# Gr√°fico de dispers√£o por esp√©cie
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Distribui√ß√£o das Esp√©cies de Iris",
x = "Sepal Length", y = "Sepal Width") +
theme_minimal()
# 70% treino, 30% teste
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[index, ]
test_data  <- iris[-index, ]
svm_model <- svm(Species ~ ., data = train_data, kernel = "linear")
svm_pred <- predict(svm_model, test_data)
# Avalia√ß√£o
svm_cm <- confusionMatrix(svm_pred, test_data$Species)
svm_cm$overall['Accuracy']
cm_df <- as.data.frame(as.table(svm_cm$table))
ggplot(cm_df, aes(x = Prediction, y = Reference, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), size = 5) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(title = "Matriz de Confus√£o - SVM") +
theme_minimal()
library(shiny)
library(ggplot2)
library(dplyr)
# Dataset de exemplo (vamos simular dados para este exemplo)
set.seed(123)
dados <- data.frame(
ano = rep(2010:2020, each = 5),
regiao = rep(c("Norte", "Nordeste", "Centro-Oeste", "Sudeste", "Sul"), times = 11),
taxa_desemprego = round(runif(55, 4, 14), 1)
)
# Interface
ui <- fluidPage(
titlePanel("Taxa de Desemprego por Regi√£o (2010‚Äì2020)"),
sidebarLayout(
sidebarPanel(
selectInput("regiao", "Selecione a Regi√£o:", choices = unique(dados$regiao), selected = "Sudeste", multiple = TRUE)
),
mainPanel(
plotOutput("plotDesemprego")
)
)
)
# Servidor
server <- function(input, output) {
dados_filtrados <- reactive({
dados %>% filter(regiao %in% input$regiao)
})
output$plotDesemprego <- renderPlot({
ggplot(dados_filtrados(), aes(x = ano, y = taxa_desemprego, color = regiao)) +
geom_line(size = 1.5) +
geom_point() +
theme_minimal() +
labs(x = "Ano", y = "Taxa de Desemprego (%)")
})
}
# Execu√ß√£o
shinyApp(ui = ui, server = server)
# Pacotes
library(cluster)
library(dbscan)
library(ggplot2)
library(dplyr)
library(factoextra)
# Dados
data(iris)
dados <- scale(iris[, 1:4])  # padronizar
# PCA
pca <- prcomp(dados)
pca_df <- as.data.frame(pca$x[, 1:2])  # apenas os dois primeiros componentes
## Agrupamento hier√°rquico
hc <- hclust(dist(dados), method = "ward.D2")
grupos_hc <- cutree(hc, k = 3)
## DBSCAN
db <- dbscan(dados, eps = 0.6, minPts = 5)
## MeanShift (aproxima√ß√£o usando density peaks via fpc)
# Alternativa vi√°vel em R: usar cluster::pam sobre estimativa de densidade
densidade <- density(pca_df$PC1 + pca_df$PC2)
centros <- which(densidade$y > quantile(densidade$y, 0.75))
grupos_ms <- pam(dados, k = 3)$clustering
# Visualiza√ß√£o
pca_df$HC <- factor(grupos_hc)
pca_df$DBSCAN <- factor(db$cluster)
pca_df$MS <- factor(grupos_ms)
# Plot exemplo para compara√ß√£o
ggplot(pca_df, aes(PC1, PC2, color = HC)) + geom_point(size = 3) + ggtitle("Hier√°rquico")
ggplot(pca_df, aes(PC1, PC2, color = DBSCAN)) + geom_point(size = 3) + ggtitle("DBSCAN")
ggplot(pca_df, aes(PC1, PC2, color = MS)) + geom_point(size = 3) + ggtitle("MeanShift (simulado)")
# Carrega bibliotecas necessarias para o processamento
library("tidyquant")
# Carrega bibliotecas necessarias para o processamento
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- fread('LOA_FINAL_GND_4.txt', sep = ';')
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- fread('SIGA_BRASIL_2020.csv', sep = ';')
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- read.csv('SIGA_BRASIL_2020.csv', sep = ';')
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv', sep = ';')
# Leitura da tabela via read.csv
setwd()
# Leitura da tabela via read.csv
caminho <- getwd()
caminho
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv', sep = ';')
# Carrega bibliotecas necessarias para o processamento
#install.packages("sf")
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv')
# Leitura da tabela via read.csv
caminho ='E:/Alex/Livano/IPEA/ipea-promob/dados_estat√≠sticos/Demanda - Nelson/infere/script_R/'
SIGA_BRASIL_2020 <- read.csv(caminho + 'SIGA_BRASIL_2020.csv')
# Leitura da tabela via read.csv
caminho ='E:/Alex/Livano/IPEA/ipea-promob/dados_estat√≠sticos/Demanda - Nelson/infere/script_R/'
SIGA_BRASIL_2020 <- read.csv(caminho ,'SIGA_BRASIL_2020.csv')
# Leitura da tabela via read.csv
caminho ='E:/Alex/Livano/IPEA/ipea-promob/dados_estat√≠sticos/Demanda - Nelson/infere/script_R/'
arquivo = caminho + 'SIGA_BRASIL_2020.csv'
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('SIGA_BRASIL_2020.csv')
# Carrega bibliotecas necessarias para o processamento
#install.packages("sf")
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('dados_normalizados_siga_brasil.csv')
# Leitura da tabela via read.csv
SIGA_BRASIL_2020 <- read.csv('dados_normalizados_siga_brasil.csv')
# Carrega bibliotecas necessarias para o processamento
library("tidyquant")
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
# Leitura da tabela via fread
LOA_FINAL_GND_4 <- read.csv('LOA_2020.csv')
knitr::opts_chunk$set(echo = TRUE)
library("openxlsx")
library("tidyverse")
library("readxl")
library("Lahman")
library("sqldf")
library("lubridate")
require("data.table")
library("rlang")
library("zoo")
library("anytime")
library("stringr")
library("readxlsb")
library("tidyr")
library("readxl")
library("dplyr")
library("openxlsx")
library("geobr")
library("BETS")
library("scales")
library(stringi)
library(shiny); runApp('E:/Alex/2025/UCB/Semana de TI/BI na Pr√°tica/Aula - BI na Pr√°tica/P_01_Scatter_Plot-Dispers√£o.R')
library(shiny)
library(plotly)
ui <- fluidPage(
titlePanel("üç∑ Scatter Plot - Rela√ß√£o entre Ingredientes"),
sidebarLayout(
sidebarPanel(
selectInput("x_axis", "Selecione o eixo X:", choices = colnames(datasets::wine)[1:13], selected = "Alcohol"),
selectInput("y_axis", "Selecione o eixo Y:", choices = colnames(datasets::wine)[1:13], selected = "Malic"),
),
mainPanel(
plotlyOutput("scatterPlot")
)
)
)
library(shiny)
library(plotly)
library(dplyr)
#Carrega conjunto de dados Iris
data(iris)
iris_df <- iris
head(iris_df)
summary(iris_df)
write.csv(iris, "iris.csv", row.names = FALSE)
write.csv(iris, "E:\Alex\2025\UCB\Semana de TI\BI na Pr√°tica\Oficina_BI_na_Pr√°tica\R\iris.csv", row.names = FALSE)
write.csv(iris, "E:/Alex/2025/UCB/Semana de TI/BI na Pr√°tica/Oficina_BI_na_Pr√°tica/R/iris.csv", row.names = FALSE)
library(shiny); runApp('E:/Alex/2025/UCB/Semana de TI/BI na Pr√°tica/Oficina_BI_na_Pr√°tica/R/P_05_Painel_Completo_iris.r')
runApp('E:/Alex/2025/UCB/Semana de TI/BI na Pr√°tica/Oficina_BI_na_Pr√°tica/R/P_05_Painel_Completo_iris.r')
